{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework 2 - Classification\n",
    "\n",
    "In this exercise you will use scikit-learn, a popular machine learning package in python to train and tune a classifier. A particularly useful feature is that all classifiers (and linear models) are called using the same API, so it is easy to test between different models (see the sklearn-intro notebook for examples). So in this exercise we will a classification technique (logistic regression) that is representative of methods and challenges you will encounter when using any classification method.\n",
    "\n",
    "\n",
    "## Dataset\n",
    "We will be using a banking marketing dataset. \n",
    "The dataset is associated with direct marketing campaigns of a banking institution. Your job is to find out the best strategies to improve for the next marketing campaign. How can the bank have a greater effectiveness for future marketing campaigns? In order to answer this, we have to analyze the last marketing campaign the bank performed and identify the patterns that will help us find conclusions in order to develop future strategies.\n",
    "\n",
    "You have to predict whether a customer subscribes for term deposit or not using the following attributes: \n",
    "\n",
    "1 - age (numeric)<br>\n",
    "2 - job : type of job (categorical: 'admin.','blue-collar','entrepreneur','housemaid','management','retired','self-employed','services','student','technician','unemployed','unknown')<br>\n",
    "3 - marital : marital status (categorical: 'divorced','married','single','unknown'; note: 'divorced' means divorced or widowed)<br>\n",
    "4 - education (categorical: 'basic.4y','basic.6y','basic.9y','high.school','illiterate','professional.course','university.degree','unknown')<br>\n",
    "5 - default: has credit in default? (categorical: 'no','yes','unknown')<br>\n",
    "6 - balance: balance amount (numeric)<br>\n",
    "7 - housing: has housing loan? (categorical: 'no','yes','unknown')<br>\n",
    "8 - loan: has personal loan? (categorical: 'no','yes','unknown')<br>\n",
    "8 - contact: contact communication type (categorical: 'cellular','telephone')<br>\n",
    "9 - month: last contact month of year (categorical: 'jan', 'feb', 'mar', ..., 'nov', 'dec')<br>\n",
    "10 - day_of_week: last contact day of the week (categorical: 'mon','tue','wed','thu','fri')<br>\n",
    "12 - campaign: number of contacts performed during this campaign and for this client (numeric, includes last contact)<br>\n",
    "13 - pdays: number of days that passed by after the client was last contacted from a previous campaign (numeric; 999 means client was not previously contacted)<br>\n",
    "14 - previous: number of contacts performed before this campaign and for this client (numeric)<br>\n",
    "15 - poutcome: outcome of the previous marketing campaign (categorical: 'failure','nonexistent','success')<br>\n",
    "\n",
    "features_ex2.xlsx contains the features. It has 4521 records. First 3165 observations are used for training dataset, next 678 observations are used for cross validation dataset and final 678 observations are used for test dataset.\n",
    "\n",
    "label_ex2.xlsx contains the label: \"yes\" or \"no\". First 3165 observations are used for training dataset, next 678 observations are used for cross validation dataset. Labels for test dataset are not provided to you because in a real world scenario you will not know the true values for your test set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.read_excel(\"features_ex2.xlsx\")\n",
    "#X.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = pd.read_excel(\"label_ex2.xlsx\")\n",
    "#y.head(20)\n",
    "#y.groupby('y').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    3405\n",
       "1     438\n",
       "Name: y, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_num = y.replace('no',0)\n",
    "y_num = y_num.replace('yes',1)\n",
    "y_num['y'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "categories = ['job','marital','education','default','housing','loan','contact','month','poutcome']\n",
    "categorical = pd.get_dummies(X[categories])\n",
    "continuous = X.drop(columns=categories)\n",
    "X = pd.concat([continuous,categorical],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>balance</th>\n",
       "      <th>day</th>\n",
       "      <th>campaign</th>\n",
       "      <th>pdays</th>\n",
       "      <th>previous</th>\n",
       "      <th>job_admin.</th>\n",
       "      <th>job_blue-collar</th>\n",
       "      <th>job_entrepreneur</th>\n",
       "      <th>job_housemaid</th>\n",
       "      <th>...</th>\n",
       "      <th>month_jun</th>\n",
       "      <th>month_mar</th>\n",
       "      <th>month_may</th>\n",
       "      <th>month_nov</th>\n",
       "      <th>month_oct</th>\n",
       "      <th>month_sep</th>\n",
       "      <th>poutcome_failure</th>\n",
       "      <th>poutcome_other</th>\n",
       "      <th>poutcome_success</th>\n",
       "      <th>poutcome_unknown</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "      <td>1787</td>\n",
       "      <td>19</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>33</td>\n",
       "      <td>4789</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>339</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>35</td>\n",
       "      <td>1350</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>330</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>30</td>\n",
       "      <td>1476</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>59</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 50 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   age  balance  day  campaign  pdays  previous  job_admin.  job_blue-collar  \\\n",
       "0   30     1787   19         1     -1         0           0                0   \n",
       "1   33     4789   11         1    339         4           0                0   \n",
       "2   35     1350   16         1    330         1           0                0   \n",
       "3   30     1476    3         4     -1         0           0                0   \n",
       "4   59        0    5         1     -1         0           0                1   \n",
       "\n",
       "   job_entrepreneur  job_housemaid  ...  month_jun  month_mar  month_may  \\\n",
       "0                 0              0  ...          0          0          0   \n",
       "1                 0              0  ...          0          0          1   \n",
       "2                 0              0  ...          0          0          0   \n",
       "3                 0              0  ...          1          0          0   \n",
       "4                 0              0  ...          0          0          1   \n",
       "\n",
       "   month_nov  month_oct  month_sep  poutcome_failure  poutcome_other  \\\n",
       "0          0          1          0                 0               0   \n",
       "1          0          0          0                 1               0   \n",
       "2          0          0          0                 1               0   \n",
       "3          0          0          0                 0               0   \n",
       "4          0          0          0                 0               0   \n",
       "\n",
       "   poutcome_success  poutcome_unknown  \n",
       "0                 0                 1  \n",
       "1                 0                 0  \n",
       "2                 0                 0  \n",
       "3                 0                 1  \n",
       "4                 0                 1  \n",
       "\n",
       "[5 rows x 50 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#splitting data into train, cv and test set (70:15:15 ratio)\n",
    "X_train = X.iloc[0:3165,:]\n",
    "y_train = y_num.iloc[0:3165,:]\n",
    "X_cv = X.iloc[3165:3843,:]\n",
    "y_cv = y_num.iloc[3165:3843,:]\n",
    "X_test = X.iloc[3843:4521,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "678"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    2799\n",
       "1     366\n",
       "Name: y, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train['y'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train (3165, 50)\n",
      "y_train (3165, 1)\n",
      "X_cv (678, 50)\n",
      "y_cv (678, 1)\n",
      "X_test (678, 50)\n"
     ]
    }
   ],
   "source": [
    "print(\"X_train \"+ str(X_train.shape))\n",
    "print(\"y_train \"+ str(y_train.shape))\n",
    "print(\"X_cv \"+ str(X_cv.shape))\n",
    "print(\"y_cv \"+ str(y_cv.shape))\n",
    "print(\"X_test \"+ str(X_test.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Standardization\n",
    "\n",
    "As discussed in previous exercise, standardization is important when a number of features with different scales are involed. \n",
    "\n",
    "Q. Use StandardScaler from sklearn.preprocessing to standardize the continuous features. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "continuous_variables = ['age', 'balance', 'day', 'campaign', 'pdays', 'previous']\n",
    "\n",
    "# Use the above list to replace the continuous columns in X_train to scaled columns. Use fit_transform method.\n",
    "X_train[continuous_variables] = scaler.fit_transform(X_train[continuous_variables])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train[continuous_variables]\n",
    "# Similarily use the above list to replace the continuous columns in X_cv and X_test to scaled columns. \n",
    "# Use transform method.\n",
    "### WRITE CODE HERE\n",
    "X_cv[continuous_variables] = scaler.transform(X_cv[continuous_variables])\n",
    "X_test[continuous_variables] = scaler.transform(X_test[continuous_variables])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification\n",
    "\n",
    "As previously mentioned, the scikit-learn classification API makes it easy to train a classifier. \n",
    "\n",
    "\n",
    "Q. Use LogisticRegression from sklearn.linear_model to make a logistic regression classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, initialize the classifier with default parameters\n",
    "\n",
    "# then fit the classifier on training data and labels\n",
    "\n",
    "### WRITE CODE HERE\n",
    "#logR = LogisticRegression()\n",
    "clf =  LogisticRegression().fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict the output for cross validation dataset\n",
    "\n",
    "### WRITE CODE HERE\n",
    "y_cv_hat = clf.predict(X_cv)\n",
    "prob = clf.predict_proba(X_cv)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implement precision(), recall(), accuracy() in exercise_2.py, and use them below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8908554572271387\n",
      "0.45\n",
      "0.125\n"
     ]
    }
   ],
   "source": [
    "from classification_utils import accuracy, precision, recall\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# Using the predictions to calculate accuracy, precision, recall\n",
    "\n",
    "### WRITE CODE HERE\n",
    "\n",
    "acc = accuracy(y_cv,y_cv_hat)\n",
    "print(acc)\n",
    "\n",
    "#tn, fp, fn, tp = confusion_matrix(y_cv, y_cv_hat).ravel()\n",
    "#print(tn, fp, fn, tp)\n",
    "#(tp+tn)/(tp+tn+fp+fn)\n",
    "\n",
    "prec = precision(y_cv,y_cv_hat)\n",
    "print(prec)\n",
    "\n",
    "recall=recall(y_cv,y_cv_hat)\n",
    "print(recall)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q. Accuracy<br>\n",
    "Ans - 0.8908554572271387\n",
    "\n",
    "Q. Precision<br>\n",
    "Ans - 0.45\n",
    "\n",
    "Q. Recall<br>\n",
    "Ans - 0.125\n",
    "\n",
    "Q. Which metric (accuracy, precision, recall) is more appropriate and in what cases? Will there be scenarios where it is better to use precision than accuracy? Explain. <br>\n",
    "Ans -  Accuracy simply measures the number of correct predicted samples over the total number of samples. For instance, if the classifier is 89% correct, it means that out of 100 instances it correctly predicts the class for 89 of them. Accuracy, by itself, however, is not a good measure of evaluating <br>\n",
    "Precision is a good measure of exactness and to determine situations when the costs of False Positive is high, eg cancer detection, or national security alarms.  <br> \n",
    "Recall or Sensitivity is about completeness: it actually calculates how many of the Actual Positives our model captures through labeling it as Positive. When there is a high cost associated with a false negative, it is better to use recall. \n",
    "\n",
    "\n",
    "Q. Which metric is suitable in this case? <br>\n",
    "Ans - Accuracy should be used in this case for banking system"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ROC curve\n",
    "\n",
    "Q. Use roc_Curve from sklearn.metrics and use matplotlib.pyplot to plot the ROC curve. USe cv set to make predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC: 0.778\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import roc_auc_score\n",
    "# calculate the fpr and tpr for all thresholds of the classification\n",
    "\n",
    "### WRITE CODE HERE\n",
    "#y_num = y.replace('no',0)\n",
    "#y_num = y_num.replace('yes',1)\n",
    "\n",
    "fpr, tpr, thresholds = roc_curve(y_cv, prob[:,1])\n",
    "#print(thresholds.shape)\n",
    "#print(thresholds,fpr,tpr)\n",
    "\n",
    "auc = roc_auc_score(y_cv, prob[:,1])\n",
    "print('AUC: %.3f' % auc)\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "# Plot the ROC curve by giving appropriate names for title and axes. \n",
    "\n",
    "### WRITE CODE HERE\n",
    "plt.plot(fpr, tpr, 'b',label='ROC curve (auc area = %0.2f)' % auc)\n",
    "plt.legend(loc = 'lower right')\n",
    "plt.plot([0, 1], [0, 1],'r--')\n",
    "plt.xlim([0, 1])\n",
    "plt.ylim([0, 1])\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.title('Receiver operating characteristic')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q. What is the AUC obtained?<br>\n",
    "Ans: 0.779"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculation of AUC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameters\n",
    "\n",
    "\"Model tuning\" refers to model adjustments to better fit the data. This is separate from \"fitting\" or \"training\" the model. The fitting/training procedure is governed by the amount and quality of your training data, as the fitting algorithm is unique to each classifier (e.g. logistic regression or random forest). \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build a model with hyperparameter 'C' set to 0.1 and penalty set to 'l1'. Make predictions on cross validation set and compute accuracy, precision and recall. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8982300884955752\n",
      "0.6\n",
      "0.125\n",
      "0.20689655172413793\n"
     ]
    }
   ],
   "source": [
    "### WRITE CODE HERE\n",
    "clf1 =  LogisticRegression(C=0.1,penalty='l1').fit(X_train,y_train)\n",
    "y_cv_hat1 = clf1.predict(X_cv)\n",
    "\n",
    "from classification_utils import accuracy, precision, recall\n",
    "\n",
    "# Using the predictions to calculate accuracy, precision, recall\n",
    "\n",
    "accuracy_1 = accuracy(y_cv,y_cv_hat1)\n",
    "print(accuracy_1)\n",
    "\n",
    "precision_1 = precision(y_cv,y_cv_hat1)\n",
    "print(precision_1)\n",
    "\n",
    "recall_1=recall(y_cv,y_cv_hat1)\n",
    "print(recall_1)\n",
    "\n",
    "f1 = (2*precision_1*recall_1)/(precision_1+recall_1)\n",
    "print(f1)\n",
    "#tn, fp, fn, tp = confusion_matrix(y_cv, y_cv_hat1).ravel()\n",
    "#print(tn, fp, fn, tp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build a model with hyperparameter 'C' set to 0.5 and penalty set to 'l1'. Make predictions on cross validation set and compute accuracy, precision and recall. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8938053097345132\n",
      "0.5\n",
      "0.1388888888888889\n",
      "0.2173913043478261\n"
     ]
    }
   ],
   "source": [
    "### WRITE CODE HERE\n",
    "clf2 =  LogisticRegression(C=0.5,penalty='l1').fit(X_train,y_train)\n",
    "y_cv_hat2 = clf2.predict(X_cv)\n",
    "\n",
    "from classification_utils import accuracy, precision, recall\n",
    "\n",
    "# Using the predictions to calculate accuracy, precision, recall\n",
    "\n",
    "accuracy_2 = accuracy(y_cv,y_cv_hat2)\n",
    "print(accuracy_2)\n",
    "\n",
    "precision_2 = precision(y_cv,y_cv_hat2)\n",
    "print(precision_2)\n",
    "\n",
    "recall_2=recall(y_cv,y_cv_hat2)\n",
    "print(recall_2)\n",
    "f2 = (2*precision_2*recall_2)/(precision_2+recall_2)\n",
    "print(f2)\n",
    "#tn, fp, fn, tp = confusion_matrix(y_cv, y_cv_hat2).ravel()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build a model with hyperparameter 'C' set to 0.1 and penalty set to 'l2'. Make predictions on cross validation set and compute accuracy, precision and recall. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8982300884955752\n",
      "0.6\n",
      "0.125\n",
      "0.20689655172413793\n"
     ]
    }
   ],
   "source": [
    "### WRITE CODE HERE\n",
    "clf3 =  LogisticRegression(C=0.1,penalty='l2').fit(X_train,y_train)\n",
    "y_cv_hat3 = clf3.predict(X_cv)\n",
    "\n",
    "from classification_utils import accuracy, precision, recall\n",
    "\n",
    "# Using the predictions to calculate accuracy, precision, recall\n",
    "\n",
    "accuracy_3 = accuracy(y_cv,y_cv_hat3)\n",
    "print(accuracy_3)\n",
    "\n",
    "precision_3 = precision(y_cv,y_cv_hat3)\n",
    "print(precision_3)\n",
    "\n",
    "recall_3=recall(y_cv,y_cv_hat3)\n",
    "print(recall_3)\n",
    "f3 = (2*precision_3*recall_3)/(precision_3+recall_3)\n",
    "print(f3)\n",
    "#tn, fp, fn, tp = confusion_matrix(y_cv, y_cv_hat3).ravel()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build a model with hyperparameter 'C' set to 0.5 and penalty set to 'l2'. Make predictions on cross validation set and compute accuracy, precision and recall. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8923303834808259\n",
      "0.47368421052631576\n",
      "0.125\n",
      "0.19780219780219782\n"
     ]
    }
   ],
   "source": [
    "### WRITE CODE HERE\n",
    "clf4 =  LogisticRegression(C=0.5,penalty='l2').fit(X_train,y_train)\n",
    "y_cv_hat4 = clf4.predict(X_cv)\n",
    "\n",
    "from classification_utils import accuracy, precision, recall\n",
    "\n",
    "# Using the predictions to calculate accuracy, precision, recall\n",
    "\n",
    "accuracy_4 = accuracy(y_cv,y_cv_hat4)\n",
    "print(accuracy_4)\n",
    "\n",
    "precision_4 = precision(y_cv,y_cv_hat4)\n",
    "print(precision_4)\n",
    "\n",
    "recall_4=recall(y_cv,y_cv_hat4)\n",
    "print(recall_4)\n",
    "f4 = (2*precision_4*recall_4)/(precision_4+recall_4)\n",
    "print(f4)\n",
    "#tn, fp, fn, tp = confusion_matrix(y_cv, y_cv_hat4).ravel()\n",
    "#print(tn, fp, fn, tp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q. Which of the above models is better? <br>\n",
    "Ans- "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test set\n",
    "\n",
    "You have worked on training and cv dataset so far, but testing data does not include the labels. Choose the best hyperparameter values as seen in previous section and build a model. Use this model to make predictions on test set. You will submit a csv file containing your predictions names as predictions.csv.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      y\n",
      "0    no\n",
      "1    no\n",
      "2    no\n",
      "3    no\n",
      "4    no\n",
      "..   ..\n",
      "673  no\n",
      "674  no\n",
      "675  no\n",
      "676  no\n",
      "677  no\n",
      "\n",
      "[678 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "##########################################\n",
    "### Construct your final logistic regression using the best hyperparameters obtained above(C and penalty) ###\n",
    "final_model = LogisticRegression(C=0.1,penalty='l2')\n",
    "final_model.fit(X_train, y_train)\n",
    "predicted = final_model.predict(X_test)\n",
    "predicted_df = pd.DataFrame({'y':predicted})\n",
    "\n",
    "predicted_df = predicted_df.replace(0,'no')\n",
    "predicted_df = predicted_df.replace(1,'yes')\n",
    "print(predicted_df)\n",
    "predicted_df.to_csv('predicted_y.csv',index = None)\n",
    "\n",
    "### save into csv with column heading as \"y\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#end "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
